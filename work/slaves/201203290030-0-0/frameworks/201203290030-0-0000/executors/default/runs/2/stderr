I0329 00:31:14.140542 22083 launcher.cpp:342] ExecutorLauncher::setupEnvironment
I0329 00:31:14.140671 22083 launcher.cpp:347] ExecutorLauncher::setupEnvironment: MESOS_DIRECTORY: /media/LinuxShare2/mesos/work/slaves/201203290030-0-0/frameworks/201203290030-0-0000/executors/default/runs/2
I0329 00:31:14.141023 22083 launcher.cpp:349] ExecutorLauncher::setupEnvironment: MESOS_SLAVE_PID: slave@192.168.1.64:33399
I0329 00:31:14.141127 22083 launcher.cpp:351] ExecutorLauncher::setupEnvironment: MESOS_FRAMEWORK_ID: 201203290030-0-0000
I0329 00:31:14.141262 22083 launcher.cpp:353] ExecutorLauncher::setupEnvironment: MESOS_EXECUTOR_ID: default
I0329 00:31:14.141394 22083 launcher.cpp:361] ExecutorLauncher::setupEnvironment: MESOS_HOME: /media/LinuxShare2/mesos
12/03/29 00:31:14 INFO spark.Executor: Running task ID 10
12/03/29 00:31:14 INFO spark.Executor: Running task ID 13
12/03/29 00:31:14 INFO spark.Executor: Running task ID 12
12/03/29 00:31:14 INFO spark.Executor: Running task ID 11
java.io.IOException: failure to login
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:433)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:395)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:1445)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: javax.security.auth.login.LoginException: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.KerberosName
	at org.apache.hadoop.security.User.<init>(User.java:44)
	at org.apache.hadoop.security.User.<init>(User.java:39)
	at org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:784)
	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:698)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:696)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:695)
	at javax.security.auth.login.LoginContext.login(LoginContext.java:595)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:414)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:395)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:1445)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)

	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:887)
	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:698)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:696)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:695)
	at javax.security.auth.login.LoginContext.login(LoginContext.java:595)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:414)
	... 18 more
java.io.IOException: failure to login
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:433)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:395)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:1445)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: javax.security.auth.login.LoginException: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.KerberosName
	at org.apache.hadoop.security.User.<init>(User.java:44)
	at org.apache.hadoop.security.User.<init>(User.java:39)
	at org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:784)
	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:698)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:696)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:695)
	at javax.security.auth.login.LoginContext.login(LoginContext.java:595)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:414)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:395)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:1445)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)

	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:887)
	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:698)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:696)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:695)
	at javax.security.auth.login.LoginContext.login(LoginContext.java:595)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:414)
	... 18 more
java.io.IOException: failure to login
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:433)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:395)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:1445)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: javax.security.auth.login.LoginException: java.lang.NoClassDefFoundError: Could not initialize class org.apache.hadoop.security.KerberosName
	at org.apache.hadoop.security.User.<init>(User.java:44)
	at org.apache.hadoop.security.User.<init>(User.java:39)
	at org.apache.hadoop.security.UserGroupInformation$HadoopLoginModule.commit(UserGroupInformation.java:111)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:616)
	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:784)
	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:698)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:696)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:695)
	at javax.security.auth.login.LoginContext.login(LoginContext.java:595)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:414)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:395)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:1445)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)

	at javax.security.auth.login.LoginContext.invoke(LoginContext.java:887)
	at javax.security.auth.login.LoginContext.access$000(LoginContext.java:203)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:698)
	at javax.security.auth.login.LoginContext$4.run(LoginContext.java:696)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.login.LoginContext.invokePriv(LoginContext.java:695)
	at javax.security.auth.login.LoginContext.login(LoginContext.java:595)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:414)
	... 18 more
12/03/29 00:31:15 ERROR spark.Executor: Exception in task ID 13
java.lang.NoClassDefFoundError: org/apache/commons/lang/StringUtils
	at org.apache.hadoop.metrics2.lib.MetricMutableStat.<init>(MetricMutableStat.java:59)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.<init>(MetricsSystemImpl.java:75)
	at org.apache.hadoop.metrics2.impl.MetricsSystemImpl.<init>(MetricsSystemImpl.java:120)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.<init>(DefaultMetricsSystem.java:37)
	at org.apache.hadoop.metrics2.lib.DefaultMetricsSystem.<clinit>(DefaultMetricsSystem.java:34)
	at org.apache.hadoop.security.UgiInstrumentation.create(UgiInstrumentation.java:51)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:196)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:159)
	at org.apache.hadoop.security.UserGroupInformation.isSecurityEnabled(UserGroupInformation.java:216)
	at org.apache.hadoop.security.KerberosName.<clinit>(KerberosName.java:83)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:189)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:159)
	at org.apache.hadoop.security.UserGroupInformation.isSecurityEnabled(UserGroupInformation.java:216)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:409)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:395)
	at org.apache.hadoop.fs.FileSystem$Cache$Key.<init>(FileSystem.java:1445)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1346)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:254)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:187)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.lang.ClassNotFoundException: org.apache.commons.lang.StringUtils
	at java.net.URLClassLoader$1.run(URLClassLoader.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at scala.tools.nsc.util.ScalaClassLoader$URLClassLoader.scala$tools$nsc$util$ScalaClassLoader$$super$findClass(ScalaClassLoader.scala:88)
	at scala.tools.nsc.util.ScalaClassLoader$class.findClass(ScalaClassLoader.scala:44)
	at scala.tools.nsc.util.ScalaClassLoader$URLClassLoader.findClass(ScalaClassLoader.scala:88)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:321)
	at scala.tools.nsc.util.ScalaClassLoader$URLClassLoader.scala$tools$nsc$util$ScalaClassLoader$$super$loadClass(ScalaClassLoader.scala:88)
	at scala.tools.nsc.util.ScalaClassLoader$class.loadClass(ScalaClassLoader.scala:50)
	at scala.tools.nsc.util.ScalaClassLoader$URLClassLoader.loadClass(ScalaClassLoader.scala:88)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:266)
	... 32 more
