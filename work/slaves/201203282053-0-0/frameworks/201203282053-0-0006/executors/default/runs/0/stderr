I0328 21:11:34.234644 20429 launcher.cpp:341] ExecutorLauncher::setupEnvironment
I0328 21:11:34.234747 20429 launcher.cpp:346] ExecutorLauncher::setupEnvironment: MESOS_DIRECTORY: /media/LinuxShare2/mesos/work/slaves/201203282053-0-0/frameworks/201203282053-0-0006/executors/default/runs/0
I0328 21:11:34.235368 20429 launcher.cpp:348] ExecutorLauncher::setupEnvironment: MESOS_SLAVE_PID: slave@192.168.1.64:59679
I0328 21:11:34.235457 20429 launcher.cpp:350] ExecutorLauncher::setupEnvironment: MESOS_FRAMEWORK_ID: 201203282053-0-0006
I0328 21:11:34.235564 20429 launcher.cpp:352] ExecutorLauncher::setupEnvironment: MESOS_EXECUTOR_ID: default
I0328 21:11:34.235677 20429 launcher.cpp:360] ExecutorLauncher::setupEnvironment: MESOS_HOME: /media/LinuxShare2/mesos
12/03/28 21:11:35 INFO spark.Executor: Running task ID 1
12/03/28 21:11:35 INFO spark.Executor: Running task ID 2
12/03/28 21:11:35 INFO spark.Executor: Running task ID 0
12/03/28 21:11:35 INFO spark.Executor: Running task ID 3
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 3
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 2
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 1
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 0
12/03/28 21:11:35 INFO spark.Executor: Running task ID 4
12/03/28 21:11:35 INFO spark.Executor: Running task ID 5
12/03/28 21:11:35 INFO spark.Executor: Running task ID 6
12/03/28 21:11:35 INFO spark.Executor: Running task ID 7
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 6
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 7
12/03/28 21:11:35 INFO spark.Executor: Running task ID 8
12/03/28 21:11:35 INFO spark.Executor: Running task ID 9
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 4
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 5
12/03/28 21:11:35 INFO spark.Executor: Running task ID 10
12/03/28 21:11:35 INFO spark.Executor: Running task ID 11
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 8
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 9
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 10
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 11
12/03/28 21:11:35 INFO spark.Executor: Running task ID 12
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:35 INFO spark.Executor: Finished task ID 12
12/03/28 21:11:35 INFO spark.Executor: Running task ID 13
12/03/28 21:11:35 INFO spark.Executor: Running task ID 14
12/03/28 21:11:35 INFO spark.Executor: Running task ID 15
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 14
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 15
12/03/28 21:11:36 INFO spark.Executor: Running task ID 16
12/03/28 21:11:36 INFO spark.Executor: Running task ID 17
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 13
12/03/28 21:11:36 INFO spark.Executor: Running task ID 18
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 16
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 17
12/03/28 21:11:36 INFO spark.Executor: Running task ID 19
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 18
12/03/28 21:11:36 INFO spark.Executor: Running task ID 20
12/03/28 21:11:36 INFO spark.Executor: Running task ID 21
12/03/28 21:11:36 INFO spark.Executor: Running task ID 22
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 19
12/03/28 21:11:36 INFO spark.Executor: Running task ID 23
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 20
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Running task ID 24
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 22
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 21
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 23
12/03/28 21:11:36 INFO spark.Executor: Running task ID 25
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 24
12/03/28 21:11:36 INFO spark.Executor: Running task ID 26
12/03/28 21:11:36 INFO spark.Executor: Running task ID 27
12/03/28 21:11:36 INFO spark.Executor: Running task ID 28
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 25
12/03/28 21:11:36 INFO spark.Executor: Running task ID 29
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 26
12/03/28 21:11:36 INFO spark.Executor: Running task ID 30
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 28
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Running task ID 31
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 27
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 29
12/03/28 21:11:36 INFO spark.Executor: Running task ID 32
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 30
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 31
12/03/28 21:11:36 INFO spark.Executor: Running task ID 33
12/03/28 21:11:36 INFO spark.Executor: Running task ID 34
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 32
12/03/28 21:11:36 INFO spark.Executor: Running task ID 35
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 34
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 33
12/03/28 21:11:36 INFO spark.Executor: Running task ID 36
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 35
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 36
12/03/28 21:11:36 INFO spark.Executor: Running task ID 37
12/03/28 21:11:36 INFO spark.Executor: Running task ID 38
12/03/28 21:11:36 INFO spark.Executor: Running task ID 39
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 38
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Running task ID 40
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 37
12/03/28 21:11:36 INFO spark.Executor: Running task ID 41
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 39
12/03/28 21:11:36 INFO spark.Executor: Running task ID 42
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 40
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 41
12/03/28 21:11:36 INFO spark.Executor: Running task ID 43
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 42
12/03/28 21:11:36 INFO spark.Executor: Running task ID 44
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 43
12/03/28 21:11:36 INFO spark.Executor: Running task ID 45
12/03/28 21:11:36 INFO spark.Executor: Running task ID 46
12/03/28 21:11:36 INFO spark.Executor: Running task ID 47
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 44
12/03/28 21:11:36 INFO spark.Executor: Running task ID 48
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 46
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 45
12/03/28 21:11:36 INFO spark.Executor: Running task ID 49
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:36 INFO spark.Executor: Finished task ID 47
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 48
12/03/28 21:11:37 INFO spark.Executor: Running task ID 50
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 49
12/03/28 21:11:37 INFO spark.Executor: Running task ID 51
12/03/28 21:11:37 INFO spark.Executor: Running task ID 52
12/03/28 21:11:37 INFO spark.Executor: Running task ID 53
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 50
12/03/28 21:11:37 INFO spark.Executor: Running task ID 54
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 53
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Running task ID 55
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 52
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 51
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 54
12/03/28 21:11:37 INFO spark.Executor: Running task ID 56
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 55
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 56
12/03/28 21:11:37 INFO spark.Executor: Running task ID 57
12/03/28 21:11:37 INFO spark.Executor: Running task ID 58
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 57
12/03/28 21:11:37 INFO spark.Executor: Running task ID 59
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 58
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:219)
	at spark.RDD$$anonfun$count$1.apply(RDD.scala:217)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.SparkContext$$anonfun$runJob$3.apply(SparkContext.scala:266)
	at spark.ResultTask.run(ResultTask.scala:10)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:37 INFO spark.Executor: Finished task ID 59
12/03/28 21:11:48 INFO spark.Executor: Running task ID 60
12/03/28 21:11:48 INFO spark.Executor: Running task ID 61
12/03/28 21:11:48 INFO spark.Executor: Running task ID 62
12/03/28 21:11:48 INFO spark.Executor: Running task ID 63
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:48 INFO spark.Executor: Finished task ID 60
12/03/28 21:11:48 INFO spark.Executor: Finished task ID 61
12/03/28 21:11:48 INFO spark.Executor: Finished task ID 62
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:48 INFO spark.Executor: Finished task ID 63
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:48 INFO spark.Executor: Running task ID 64
12/03/28 21:11:48 INFO spark.Executor: Running task ID 65
12/03/28 21:11:48 INFO spark.Executor: Running task ID 66
12/03/28 21:11:48 INFO spark.Executor: Running task ID 67
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:48 INFO spark.Executor: Finished task ID 66
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:48 INFO spark.Executor: Finished task ID 65
12/03/28 21:11:48 INFO spark.Executor: Finished task ID 67
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 64
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 68
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 68
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 69
12/03/28 21:11:49 INFO spark.Executor: Running task ID 70
12/03/28 21:11:49 INFO spark.Executor: Running task ID 71
12/03/28 21:11:49 INFO spark.Executor: Running task ID 72
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 71
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 69
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 72
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Running task ID 73
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 70
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 74
12/03/28 21:11:49 INFO spark.Executor: Running task ID 75
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 76
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 73
12/03/28 21:11:49 INFO spark.Executor: Running task ID 77
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 75
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 74
12/03/28 21:11:49 INFO spark.Executor: Running task ID 78
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 76
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 79
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 77
12/03/28 21:11:49 INFO spark.Executor: Running task ID 80
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 78
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Running task ID 81
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 79
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 80
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 81
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 82
12/03/28 21:11:49 INFO spark.Executor: Running task ID 83
12/03/28 21:11:49 INFO spark.Executor: Running task ID 84
12/03/28 21:11:49 INFO spark.Executor: Running task ID 85
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 82
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 84
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 83
12/03/28 21:11:49 INFO spark.Executor: Running task ID 86
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 85
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 87
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 86
12/03/28 21:11:49 INFO spark.Executor: Running task ID 88
12/03/28 21:11:49 INFO spark.Executor: Running task ID 89
12/03/28 21:11:49 INFO spark.Executor: Running task ID 90
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 87
12/03/28 21:11:49 INFO spark.Executor: Running task ID 91
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 90
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 88
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 92
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 89
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 93
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 91
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:49 INFO spark.Executor: Running task ID 94
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 92
12/03/28 21:11:49 INFO spark.Executor: Running task ID 95
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:49 INFO spark.Executor: Finished task ID 93
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 96
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 94
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 97
12/03/28 21:11:50 INFO spark.Executor: Running task ID 98
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 95
12/03/28 21:11:50 INFO spark.Executor: Running task ID 99
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 96
12/03/28 21:11:50 INFO spark.Executor: Running task ID 100
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 98
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 97
12/03/28 21:11:50 INFO spark.Executor: Running task ID 101
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 99
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 100
12/03/28 21:11:50 INFO spark.Executor: Running task ID 102
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 103
12/03/28 21:11:50 INFO spark.Executor: Running task ID 104
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 101
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 102
12/03/28 21:11:50 INFO spark.Executor: Running task ID 105
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 104
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 103
12/03/28 21:11:50 INFO spark.Executor: Running task ID 106
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 105
12/03/28 21:11:50 INFO spark.Executor: Running task ID 107
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 106
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 108
12/03/28 21:11:50 INFO spark.Executor: Running task ID 109
12/03/28 21:11:50 INFO spark.Executor: Running task ID 110
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 107
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 111
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 108
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 109
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 110
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 112
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 111
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 112
12/03/28 21:11:50 INFO spark.Executor: Running task ID 113
12/03/28 21:11:50 INFO spark.Executor: Running task ID 114
12/03/28 21:11:50 INFO spark.Executor: Running task ID 115
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 113
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 115
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 114
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 116
12/03/28 21:11:50 INFO spark.Executor: Running task ID 117
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 118
12/03/28 21:11:50 INFO spark.Executor: Running task ID 119
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 117
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 116
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 118
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 119
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:50 INFO spark.Executor: Running task ID 120
12/03/28 21:11:50 INFO spark.Executor: Running task ID 121
12/03/28 21:11:50 INFO spark.Executor: Running task ID 122
12/03/28 21:11:50 INFO spark.Executor: Running task ID 123
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 120
12/03/28 21:11:50 INFO spark.Executor: Finished task ID 121
12/03/28 21:11:50 INFO spark.Executor: Running task ID 124
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 122
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Running task ID 125
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 123
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:51 INFO spark.Executor: Running task ID 126
12/03/28 21:11:51 INFO spark.Executor: Running task ID 127
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 125
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 124
12/03/28 21:11:51 INFO spark.Executor: Running task ID 128
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 127
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 126
12/03/28 21:11:51 INFO spark.Executor: Running task ID 129
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:51 INFO spark.Executor: Running task ID 130
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 128
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Running task ID 131
12/03/28 21:11:51 INFO spark.Executor: Running task ID 132
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 129
12/03/28 21:11:51 INFO spark.Executor: Running task ID 133
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 130
12/03/28 21:11:51 INFO spark.Executor: Running task ID 134
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 132
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 131
12/03/28 21:11:51 INFO spark.Executor: Running task ID 135
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 133
12/03/28 21:11:51 INFO spark.Executor: Running task ID 136
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 134
12/03/28 21:11:51 INFO spark.Executor: Running task ID 137
12/03/28 21:11:51 INFO spark.Executor: Running task ID 138
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 135
12/03/28 21:11:51 INFO spark.Executor: Running task ID 139
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 136
12/03/28 21:11:51 INFO spark.Executor: Running task ID 140
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 138
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 137
12/03/28 21:11:51 INFO spark.Executor: Running task ID 141
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 139
12/03/28 21:11:51 INFO spark.Executor: Running task ID 142
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 140
12/03/28 21:11:51 INFO spark.Executor: Running task ID 143
12/03/28 21:11:51 INFO spark.Executor: Running task ID 144
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 141
12/03/28 21:11:51 INFO spark.Executor: Running task ID 145
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 142
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 144
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 143
12/03/28 21:11:51 INFO spark.Executor: Running task ID 146
12/03/28 21:11:51 INFO spark.Executor: Running task ID 147
12/03/28 21:11:51 INFO spark.Executor: Running task ID 148
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 145
12/03/28 21:11:51 INFO spark.Executor: Running task ID 149
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 146
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 147
12/03/28 21:11:51 INFO spark.Executor: Running task ID 150
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:51 INFO spark.Executor: Running task ID 151
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:51 INFO spark.Executor: Finished task ID 148
12/03/28 21:11:51 INFO spark.Executor: Running task ID 152
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 149
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 150
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Running task ID 153
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 151
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:52 INFO spark.Executor: Running task ID 154
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 152
12/03/28 21:11:52 INFO spark.Executor: Running task ID 155
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 153
12/03/28 21:11:52 INFO spark.Executor: Running task ID 156
12/03/28 21:11:52 INFO spark.Executor: Running task ID 157
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 154
12/03/28 21:11:52 INFO spark.Executor: Running task ID 158
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 155
12/03/28 21:11:52 INFO spark.Executor: Running task ID 159
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 156
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 157
12/03/28 21:11:52 INFO spark.Executor: Running task ID 160
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 158
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:52 INFO spark.Executor: Running task ID 161
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 159
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:52 INFO spark.Executor: Running task ID 162
12/03/28 21:11:52 INFO spark.Executor: Running task ID 163
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 160
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:52 INFO spark.Executor: Running task ID 164
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 163
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 161
12/03/28 21:11:52 INFO spark.Executor: Running task ID 165
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 162
12/03/28 21:11:52 INFO spark.Executor: Running task ID 166
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 164
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:52 INFO spark.Executor: Running task ID 167
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 165
12/03/28 21:11:52 INFO spark.Executor: Running task ID 168
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 166
12/03/28 21:11:52 INFO spark.Executor: Running task ID 169
12/03/28 21:11:52 INFO spark.Executor: Running task ID 170
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 167
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:52 INFO spark.Executor: Running task ID 171
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 168
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:52 INFO spark.Executor: Running task ID 172
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 170
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 169
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
12/03/28 21:11:52 INFO spark.Executor: Running task ID 173
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 171
12/03/28 21:11:52 INFO spark.Executor: Running task ID 174
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 172
12/03/28 21:11:52 INFO spark.Executor: Running task ID 175
12/03/28 21:11:52 INFO spark.Executor: Running task ID 176
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 173
12/03/28 21:11:52 INFO spark.Executor: Running task ID 177
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 174
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Running task ID 178
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 175
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:52 INFO spark.Executor: Finished task ID 176
12/03/28 21:11:52 INFO spark.Executor: Running task ID 179
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:53 INFO spark.Executor: Finished task ID 177
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:53 INFO spark.Executor: Finished task ID 178
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:11:53 INFO spark.Executor: Finished task ID 179
java.io.IOException: Call to azad/192.168.1.64:54310 failed on local exception: java.io.EOFException
	at org.apache.hadoop.ipc.Client.wrapException(Client.java:775)
	at org.apache.hadoop.ipc.Client.call(Client.java:743)
	at org.apache.hadoop.ipc.RPC$Invoker.invoke(RPC.java:220)
	at $Proxy0.getProtocolVersion(Unknown Source)
	at org.apache.hadoop.ipc.RPC.getProxy(RPC.java:359)
	at org.apache.hadoop.hdfs.DFSClient.createRPCNamenode(DFSClient.java:106)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:207)
	at org.apache.hadoop.hdfs.DFSClient.<init>(DFSClient.java:170)
	at org.apache.hadoop.hdfs.DistributedFileSystem.initialize(DistributedFileSystem.java:82)
	at org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:1378)
	at org.apache.hadoop.fs.FileSystem.access$200(FileSystem.java:66)
	at org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:1390)
	at org.apache.hadoop.fs.FileSystem.get(FileSystem.java:196)
	at org.apache.hadoop.fs.Path.getFileSystem(Path.java:175)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:182)
	at com.virkaz.star.hadoopio.PipesBinaryMatrixRecordReader.next(PipesBinaryMatrixRecordReader.java:27)
	at spark.HadoopRDD$$anon$1.hasNext(HadoopRDD.scala:81)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$$anon$19.hasNext(Iterator.scala:334)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.Iterator$$anon$19.foreach(Iterator.scala:333)
	at spark.PipedRDD$$anon$2.run(PipedRDD.scala:41)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$Connection.receiveResponse(Client.java:501)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:446)
