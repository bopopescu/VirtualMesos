I0328 20:59:45.385133 15594 launcher.cpp:341] ExecutorLauncher::setupEnvironment
I0328 20:59:45.385182 15594 launcher.cpp:346] ExecutorLauncher::setupEnvironment: MESOS_DIRECTORY: /media/LinuxShare2/mesos/work/slaves/201203282053-0-0/frameworks/201203282053-0-0000/executors/default/runs/0
I0328 20:59:45.385274 15594 launcher.cpp:348] ExecutorLauncher::setupEnvironment: MESOS_SLAVE_PID: slave@192.168.1.64:59679
I0328 20:59:45.385304 15594 launcher.cpp:350] ExecutorLauncher::setupEnvironment: MESOS_FRAMEWORK_ID: 201203282053-0-0000
I0328 20:59:45.385324 15594 launcher.cpp:352] ExecutorLauncher::setupEnvironment: MESOS_EXECUTOR_ID: default
I0328 20:59:45.385351 15594 launcher.cpp:360] ExecutorLauncher::setupEnvironment: MESOS_HOME: /media/LinuxShare2/mesos
12/03/28 20:59:46 INFO spark.Executor: Running task ID 1
12/03/28 20:59:46 INFO spark.Executor: Running task ID 3
12/03/28 20:59:46 INFO spark.Executor: Running task ID 2
12/03/28 20:59:46 INFO spark.Executor: Running task ID 0
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 1
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 3
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 0
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 2
12/03/28 20:59:47 INFO spark.Executor: Running task ID 12
12/03/28 20:59:47 INFO spark.Executor: Running task ID 13
12/03/28 20:59:47 INFO spark.Executor: Running task ID 14
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 13
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 12
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 14
12/03/28 20:59:47 INFO spark.Executor: Running task ID 17
12/03/28 20:59:47 INFO spark.Executor: Running task ID 18
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 18
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 17
12/03/28 20:59:47 INFO spark.Executor: Running task ID 24
12/03/28 20:59:47 INFO spark.Executor: Running task ID 25
12/03/28 20:59:47 INFO spark.Executor: Running task ID 26
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 24
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 25
12/03/28 20:59:47 INFO spark.Executor: Finished task ID 26
12/03/28 21:00:00 INFO spark.Executor: Running task ID 30
12/03/28 21:00:00 INFO spark.Executor: Running task ID 31
12/03/28 21:00:00 INFO spark.Executor: Running task ID 32
12/03/28 21:00:00 INFO spark.Executor: Running task ID 33
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 33
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 30
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 32
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 31
12/03/28 21:00:00 INFO spark.Executor: Running task ID 39
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 39
12/03/28 21:00:00 INFO spark.Executor: Running task ID 44
12/03/28 21:00:00 INFO spark.Executor: Running task ID 45
12/03/28 21:00:00 INFO spark.Executor: Running task ID 46
12/03/28 21:00:00 INFO spark.Executor: Running task ID 47
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 44
12/03/28 21:00:00 INFO spark.Executor: Running task ID 52
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 45
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 46
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:00 INFO spark.Executor: Finished task ID 47
12/03/28 21:00:00 INFO spark.Executor: Running task ID 53
12/03/28 21:00:00 INFO spark.Executor: Running task ID 54
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:01 INFO spark.Executor: Finished task ID 52
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:01 INFO spark.Executor: Running task ID 58
12/03/28 21:00:01 INFO spark.Executor: Finished task ID 54
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:01 INFO spark.Executor: Finished task ID 53
12/03/28 21:00:01 INFO spark.Executor: Running task ID 59
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
/hadoop-distro/StdInReaderForArray: error while loading shared libraries: libTree.so: cannot open shared object file: No such file or directory
12/03/28 21:00:01 INFO spark.Executor: Finished task ID 59
12/03/28 21:00:01 INFO spark.Executor: Finished task ID 58
12/03/28 21:00:01 INFO spark.Executor: Running task ID 60
12/03/28 21:00:01 INFO spark.Executor: Running task ID 62
12/03/28 21:00:01 INFO spark.Executor: Running task ID 64
12/03/28 21:00:01 INFO spark.Executor: Running task ID 66
12/03/28 21:00:01 ERROR spark.Executor: Exception in task ID 60
java.lang.ClassNotFoundException: hadooproot.HadoopRootRDD$$anonfun$main$1
	at java.net.URLClassLoader$1.run(URLClassLoader.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:321)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:266)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at spark.Utils$$anon$1.resolveClass(Utils.scala:33)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1592)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1513)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1749)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:368)
	at spark.Utils$.deserialize(Utils.scala:35)
	at spark.Executor$TaskRunner.run(Executor.scala:68)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/28 21:00:01 ERROR spark.Executor: Exception in task ID 62
java.lang.ClassNotFoundException: hadooproot.HadoopRootRDD$$anonfun$main$1
	at java.net.URLClassLoader$1.run(URLClassLoader.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:321)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:266)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at spark.Utils$$anon$1.resolveClass(Utils.scala:33)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1592)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1513)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1749)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:368)
	at spark.Utils$.deserialize(Utils.scala:35)
	at spark.Executor$TaskRunner.run(Executor.scala:68)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/28 21:00:01 ERROR spark.Executor: Exception in task ID 64
java.lang.ClassNotFoundException: hadooproot.HadoopRootRDD$$anonfun$main$1
	at java.net.URLClassLoader$1.run(URLClassLoader.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:321)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:266)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at spark.Utils$$anon$1.resolveClass(Utils.scala:33)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1592)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1513)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1749)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:368)
	at spark.Utils$.deserialize(Utils.scala:35)
	at spark.Executor$TaskRunner.run(Executor.scala:68)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/28 21:00:01 INFO spark.Executor: Running task ID 68
