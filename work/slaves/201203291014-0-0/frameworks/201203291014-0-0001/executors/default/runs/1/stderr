I0329 10:14:38.632619  6321 launcher.cpp:342] ExecutorLauncher::setupEnvironment
I0329 10:14:38.632748  6321 launcher.cpp:347] ExecutorLauncher::setupEnvironment: MESOS_DIRECTORY: /media/LinuxShare2/mesos/work/slaves/201203291014-0-0/frameworks/201203291014-0-0001/executors/default/runs/1
I0329 10:14:38.633294  6321 launcher.cpp:349] ExecutorLauncher::setupEnvironment: MESOS_SLAVE_PID: slave@192.168.1.64:57346
I0329 10:14:38.633496  6321 launcher.cpp:351] ExecutorLauncher::setupEnvironment: MESOS_FRAMEWORK_ID: 201203291014-0-0001
I0329 10:14:38.633718  6321 launcher.cpp:353] ExecutorLauncher::setupEnvironment: MESOS_EXECUTOR_ID: default
I0329 10:14:38.634057  6321 launcher.cpp:361] ExecutorLauncher::setupEnvironment: MESOS_HOME: /media/LinuxShare2/mesos
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/spark-distro/lib_managed/jars/org.slf4j/slf4j-log4j12/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/spark-distro/lib_managed/jars/hadoop_root/slf4j-log4j12-1.4.3.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
12/03/29 10:14:39 INFO spark.Executor: Running task ID 57
12/03/29 10:14:39 INFO spark.Executor: Running task ID 58
12/03/29 10:14:39 INFO spark.Executor: Running task ID 59
12/03/29 10:14:39 INFO spark.Executor: Running task ID 60
12/03/29 10:14:39 INFO spark.Executor: Running task ID 61
12/03/29 10:14:39 INFO spark.Executor: Running task ID 62
12/03/29 10:14:39 INFO spark.Executor: Running task ID 63
12/03/29 10:14:39 INFO spark.Executor: Running task ID 64
12/03/29 10:14:39 INFO spark.CacheTracker: CachedRDD partition key is (1,1)
12/03/29 10:14:39 INFO spark.CacheTracker: Computing partition spark.HadoopSplit@692
12/03/29 10:14:39 INFO spark.CacheTracker: CachedRDD partition key is (1,5)
12/03/29 10:14:39 INFO spark.CacheTracker: Computing partition spark.HadoopSplit@696
12/03/29 10:14:40 INFO spark.CacheTracker: CachedRDD partition key is (1,2)
12/03/29 10:14:40 INFO spark.CacheTracker: Computing partition spark.HadoopSplit@693
12/03/29 10:14:40 INFO spark.CacheTracker: CachedRDD partition key is (1,6)
12/03/29 10:14:40 INFO spark.CacheTracker: Computing partition spark.HadoopSplit@697
12/03/29 10:14:40 INFO spark.CacheTracker: CachedRDD partition key is (1,4)
12/03/29 10:14:40 INFO spark.CacheTracker: Computing partition spark.HadoopSplit@695
12/03/29 10:14:40 INFO spark.CacheTracker: CachedRDD partition key is (1,0)
12/03/29 10:14:40 INFO spark.CacheTracker: Computing partition spark.HadoopSplit@691
12/03/29 10:14:40 INFO spark.CacheTracker: CachedRDD partition key is (1,7)
12/03/29 10:14:40 INFO spark.CacheTracker: Computing partition spark.HadoopSplit@698
12/03/29 10:14:40 INFO spark.CacheTracker: CachedRDD partition key is (1,3)
12/03/29 10:14:40 INFO spark.CacheTracker: Computing partition spark.HadoopSplit@694
12/03/29 10:14:41 INFO spark.LocalFileShuffle: Shuffle dir: /tmp/spark-local-3c0a4569-3811-4163-9d11-383289b55198/shuffle
12/03/29 10:14:41 INFO server.Server: jetty-7.5.3.v20111011
12/03/29 10:14:41 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:58310 STARTING
12/03/29 10:14:41 INFO spark.LocalFileShuffle: Local URI: http://192.168.1.64:58310
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 60
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 61
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 63
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 57
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 62
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 64
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 59
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 58
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 INFO spark.Executor: Running task ID 65
12/03/29 10:14:41 INFO spark.Executor: Running task ID 66
12/03/29 10:14:41 INFO spark.Executor: Running task ID 67
12/03/29 10:14:41 INFO spark.CacheTracker: CachedRDD partition key is (1,5)
12/03/29 10:14:41 INFO spark.CacheTracker: Found partition in cache!
12/03/29 10:14:41 INFO spark.Executor: Running task ID 69
12/03/29 10:14:41 INFO spark.CacheTracker: CachedRDD partition key is (1,3)
12/03/29 10:14:41 INFO spark.CacheTracker: Found partition in cache!
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 66
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
12/03/29 10:14:41 INFO spark.Executor: Running task ID 68
12/03/29 10:14:41 ERROR spark.Executor: Exception in task ID 65
java.io.NotSerializableException: org.apache.hadoop.io.Text
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1180)
	at java.io.ObjectOutputStream.defaultWriteFields(ObjectOutputStream.java:1528)
	at java.io.ObjectOutputStream.writeSerialData(ObjectOutputStream.java:1493)
	at java.io.ObjectOutputStream.writeOrdinaryObject(ObjectOutputStream.java:1416)
	at java.io.ObjectOutputStream.writeObject0(ObjectOutputStream.java:1174)
	at java.io.ObjectOutputStream.writeObject(ObjectOutputStream.java:346)
	at spark.JavaSerializationStream.writeObject(JavaSerializer.scala:7)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at spark.ShuffleMapTask$$anonfun$run$1$$anonfun$apply$mcVI$sp$1.apply(ShuffleMapTask.scala:31)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.mutable.HashMap$$anonfun$foreach$1.apply(HashMap.scala:93)
	at scala.collection.Iterator$class.foreach(Iterator.scala:660)
	at scala.collection.mutable.HashTable$$anon$1.foreach(HashTable.scala:157)
	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:190)
	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:43)
	at scala.collection.mutable.HashMap.foreach(HashMap.scala:93)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:28)
	at spark.ShuffleMapTask.run(ShuffleMapTask.scala:9)
	at spark.Executor$TaskRunner.run(Executor.scala:71)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
