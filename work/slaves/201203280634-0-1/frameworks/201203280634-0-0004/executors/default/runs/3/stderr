I0328 06:50:15.568014 25019 launcher.cpp:341] ExecutorLauncher::setupEnvironment
I0328 06:50:15.568140 25019 launcher.cpp:346] ExecutorLauncher::setupEnvironment: MESOS_DIRECTORY: /media/LinuxShare2/mesos/work/slaves/201203280634-0-1/frameworks/201203280634-0-0004/executors/default/runs/3
I0328 06:50:15.568666 25019 launcher.cpp:348] ExecutorLauncher::setupEnvironment: MESOS_SLAVE_PID: slave@192.168.1.64:49005
I0328 06:50:15.568817 25019 launcher.cpp:350] ExecutorLauncher::setupEnvironment: MESOS_FRAMEWORK_ID: 201203280634-0-0004
I0328 06:50:15.569049 25019 launcher.cpp:352] ExecutorLauncher::setupEnvironment: MESOS_EXECUTOR_ID: default
I0328 06:50:15.569293 25019 launcher.cpp:360] ExecutorLauncher::setupEnvironment: MESOS_HOME: /media/LinuxShare2/mesos
12/03/28 06:50:16 INFO spark.Executor: Running task ID 34
12/03/28 06:50:16 ERROR spark.Executor: Exception in task ID 34
java.lang.ClassNotFoundException: hadooproot.HadoopRootRDD$$anonfun$main$1
	at java.net.URLClassLoader$1.run(URLClassLoader.java:217)
	at java.security.AccessController.doPrivileged(Native Method)
	at java.net.URLClassLoader.findClass(URLClassLoader.java:205)
	at scala.tools.nsc.util.ScalaClassLoader$URLClassLoader.scala$tools$nsc$util$ScalaClassLoader$$super$findClass(ScalaClassLoader.scala:88)
	at scala.tools.nsc.util.ScalaClassLoader$class.findClass(ScalaClassLoader.scala:44)
	at scala.tools.nsc.util.ScalaClassLoader$URLClassLoader.findClass(ScalaClassLoader.scala:88)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:321)
	at scala.tools.nsc.util.ScalaClassLoader$URLClassLoader.scala$tools$nsc$util$ScalaClassLoader$$super$loadClass(ScalaClassLoader.scala:88)
	at scala.tools.nsc.util.ScalaClassLoader$class.loadClass(ScalaClassLoader.scala:50)
	at scala.tools.nsc.util.ScalaClassLoader$URLClassLoader.loadClass(ScalaClassLoader.scala:88)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:266)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:264)
	at spark.Utils$$anon$1.resolveClass(Utils.scala:33)
	at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1592)
	at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1513)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1749)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1963)
	at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1887)
	at java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1770)
	at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1346)
	at java.io.ObjectInputStream.readObject(ObjectInputStream.java:368)
	at spark.Utils$.deserialize(Utils.scala:35)
	at spark.Executor$TaskRunner.run(Executor.scala:68)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
	at java.lang.Thread.run(Thread.java:679)
